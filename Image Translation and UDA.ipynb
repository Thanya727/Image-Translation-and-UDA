{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HcOddDakISU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Compose, Resize, Grayscale, Normalize\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from itertools import cycle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnGlRwzSHE6O"
      },
      "source": [
        "# USPS to MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wk0u6oclECJk"
      },
      "outputs": [],
      "source": [
        "transform = Compose([\n",
        "        Resize(size = (28,28)),\n",
        "        Grayscale(),\n",
        "        # transforms.RandomCrop(224),\n",
        "        # transforms.RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "        Normalize(mean=[0.5], std=[0.5])\n",
        "        ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkJk-cXYnlZ0",
        "outputId": "2de67637-c6a3-4f26-e18b-0aea42b20462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 57991878.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 80811003.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 24986691.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 15191809.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/multiclass/usps.t.bz2 to data/usps.t.bz2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1831726/1831726 [00:01<00:00, 1614639.35it/s]\n"
          ]
        }
      ],
      "source": [
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = transform,\n",
        "    download = True,\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = transform\n",
        ")\n",
        "target_data = datasets.USPS(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    transform=transform,\n",
        "    download=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpv-Cvm2nswc",
        "outputId": "bd51b0d0-a238-4df3-83d6-77813062516a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "               Grayscale(num_output_channels=1)\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.5], std=[0.5])\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "print(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9zUp5n0nwos",
        "outputId": "9d747c9a-a73e-4d58-e709-a2717f37e37d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset USPS\n",
            "    Number of datapoints: 2007\n",
            "    Root location: data\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(28, 28), interpolation=bilinear, max_size=None, antialias=warn)\n",
            "               Grayscale(num_output_channels=1)\n",
            "               ToTensor()\n",
            "               Normalize(mean=[0.5], std=[0.5])\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "print(target_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txieWODpn0Mz",
        "outputId": "e948cce9-7c6a-4a29-bd71-07a4353c1904"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28])\n",
            "torch.Size([60000])\n"
          ]
        }
      ],
      "source": [
        "print(train_data.data.size())\n",
        "print(train_data.targets.size())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.targets[6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3DDsCr26CFy",
        "outputId": "751f4449-1978-43a0-eda4-0aaec3cfec47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KwroLYZ77PM",
        "outputId": "7cfafe57-c531-40a2-b0f7-44c133e1a6b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2007, 16, 16)\n"
          ]
        }
      ],
      "source": [
        "# print(target_data.data.size())\n",
        "print(target_data.data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQabRIHTn6F9",
        "outputId": "a0f68627-c23a-4e5b-ebc4-d23a7a567b03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7ce2fe1bbdf0>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7ce2fe1bbf70>,\n",
              " 'target': <torch.utils.data.dataloader.DataLoader at 0x7ce2fe21e950>}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "loaders = {\n",
        "    'train' : torch.utils.data.DataLoader(train_data,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2),\n",
        "\n",
        "    'test'  : torch.utils.data.DataLoader(test_data,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2),\n",
        "    'target' : torch.utils.data.DataLoader(target_data,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2),\n",
        "}\n",
        "loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKgW64GJpA-Q"
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=16,\n",
        "                kernel_size=5,\n",
        "                stride=1,\n",
        "                padding=2,\n",
        "            ),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, 5, 1, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        # fully connected layer, output 10 classes\n",
        "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        output = self.out(x)\n",
        "        return output, x    # return x for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoL1W9nhpcEp"
      },
      "outputs": [],
      "source": [
        "cnn = CNN()\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn.parameters(), lr = 0.01)\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fez27h-bpgR5"
      },
      "outputs": [],
      "source": [
        "def train(num_epochs, cnn, loader = loaders['train']):\n",
        "\n",
        "    cnn.train()\n",
        "\n",
        "    # Train the model\n",
        "    total_step = len(loader)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for i, (images, labels) in enumerate(loader):\n",
        "\n",
        "            # gives batch data, normalize x when iterate train_loader\n",
        "            b_x = Variable(images)   # batch x\n",
        "            b_y = Variable(labels)   # batch y\n",
        "            output = cnn(b_x)[0]\n",
        "            loss = loss_func(output, b_y)\n",
        "\n",
        "            # clear gradients for this training step\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # backpropagation, compute gradients\n",
        "            loss.backward()\n",
        "            # apply gradients\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % 100 == 0:\n",
        "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gozlG-NFqHte",
        "outputId": "718757f1-2cef-42fe-9d17-3b7eb9f2eb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/100], Loss: 0.1068\n",
            "Epoch [2/10], Step [100/100], Loss: 0.1049\n",
            "Epoch [3/10], Step [100/100], Loss: 0.0671\n",
            "Epoch [4/10], Step [100/100], Loss: 0.0683\n",
            "Epoch [5/10], Step [100/100], Loss: 0.0621\n",
            "Epoch [6/10], Step [100/100], Loss: 0.0005\n",
            "Epoch [7/10], Step [100/100], Loss: 0.0108\n",
            "Epoch [8/10], Step [100/100], Loss: 0.0106\n",
            "Epoch [9/10], Step [100/100], Loss: 0.0027\n",
            "Epoch [10/10], Step [100/100], Loss: 0.0115\n"
          ]
        }
      ],
      "source": [
        "train(num_epochs, cnn, loaders[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_-v9nDsrf7b"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader = loaders['test']):\n",
        "    # Test the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in test_loader:\n",
        "            test_output, last_layer = model(images)\n",
        "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
        "            correct += (pred_y == labels).sum().item()\n",
        "            total += len(labels)\n",
        "    accuracy = correct/total\n",
        "            #accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
        "\n",
        "    print('Test Accuracy of the model on the ' + str(total) + ' test images: %.2f' % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvzrycUSHn5b",
        "outputId": "ad93a459-5330-4d94-e6fd-84351c735dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 0.99\n"
          ]
        }
      ],
      "source": [
        "test(model = cnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpQyVByJrkFV",
        "outputId": "41adee4f-a685-4ad7-d415-de4a360362eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 2007 test images: 0.68\n"
          ]
        }
      ],
      "source": [
        "test(model = cnn, test_loader = loaders['target'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C4XvhdwR27R"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6GVHvshR32v"
      },
      "source": [
        "## After Domain Adaptation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90ATcKUgQu4W"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += residual\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrOMtQxf2iGi"
      },
      "outputs": [],
      "source": [
        "class CycleGANDiscriminator(nn.Module):\n",
        "    def __init__(self, input_channels):\n",
        "        super(CycleGANDiscriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 1, kernel_size=4, stride=1, padding=1)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return self.sigmoid(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTnFkTZcS6jd"
      },
      "outputs": [],
      "source": [
        "# Define the CycleGAN Generator\n",
        "class CycleGANGenerator(nn.Module):\n",
        "    def __init__(self, input_channels, num_res_blocks=6):\n",
        "        super(CycleGANGenerator, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(input_channels, 64, kernel_size=7, stride=1, padding=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.residual_blocks = nn.Sequential(*[ResidualBlock(256, 256) for _ in range(num_res_blocks)])\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, input_channels, kernel_size=7, stride=1, padding=3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.residual_blocks(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bifx9duANw-g"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_generated_images(generator, num_images=5):\n",
        "    generator.eval()  # Set the generator to evaluation mode\n",
        "    with torch.no_grad():\n",
        "        for _ in range(num_images):\n",
        "            # Generate a random input or use a sample from the test dataset\n",
        "            random_input = torch.randn(1, 1, image_size, image_size).to(device)\n",
        "            generated_image = generator(random_input)\n",
        "\n",
        "            # Convert the generated image tensor to a NumPy array\n",
        "            generated_image_np = generated_image.squeeze().cpu().numpy()\n",
        "\n",
        "            # Display the generated image using matplotlib\n",
        "            plt.imshow(generated_image_np, cmap='gray')\n",
        "            plt.axis('off')\n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECBYvpjeaw42",
        "outputId": "b8993b36-20c4-4f97-d924-748ea4562170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/50] [Batch 0/600] [D loss: 0.7946393489837646] [G loss: 6.076794624328613]\n",
            "[Epoch 0/50] [Batch 100/600] [D loss: 0.7283543944358826] [G loss: 1.253309726715088]\n",
            "[Epoch 0/50] [Batch 200/600] [D loss: 0.6930524110794067] [G loss: 1.2392504215240479]\n",
            "[Epoch 0/50] [Batch 300/600] [D loss: 0.625352144241333] [G loss: 1.3778417110443115]\n",
            "[Epoch 0/50] [Batch 400/600] [D loss: 0.6096433401107788] [G loss: 1.3409337997436523]\n",
            "[Epoch 0/50] [Batch 500/600] [D loss: 0.5984024405479431] [G loss: 1.3184573650360107]\n",
            "[Epoch 1/50] [Batch 0/600] [D loss: 0.6362478733062744] [G loss: 1.3242263793945312]\n",
            "[Epoch 1/50] [Batch 100/600] [D loss: 0.6667013168334961] [G loss: 1.3064451217651367]\n",
            "[Epoch 1/50] [Batch 200/600] [D loss: 0.6522871851921082] [G loss: 1.2691234350204468]\n",
            "[Epoch 1/50] [Batch 300/600] [D loss: 0.6785300970077515] [G loss: 1.2345397472381592]\n",
            "[Epoch 1/50] [Batch 400/600] [D loss: 0.6598340272903442] [G loss: 1.312556266784668]\n",
            "[Epoch 1/50] [Batch 500/600] [D loss: 0.6317901611328125] [G loss: 1.1900744438171387]\n",
            "[Epoch 2/50] [Batch 0/600] [D loss: 0.6718381643295288] [G loss: 1.1953212022781372]\n",
            "[Epoch 2/50] [Batch 100/600] [D loss: 0.702226459980011] [G loss: 1.1720588207244873]\n",
            "[Epoch 2/50] [Batch 200/600] [D loss: 0.689456045627594] [G loss: 1.1262099742889404]\n",
            "[Epoch 2/50] [Batch 300/600] [D loss: 0.6630939245223999] [G loss: 1.1909798383712769]\n",
            "[Epoch 2/50] [Batch 400/600] [D loss: 0.6875640153884888] [G loss: 1.2311888933181763]\n",
            "[Epoch 2/50] [Batch 500/600] [D loss: 0.640585720539093] [G loss: 1.204627275466919]\n",
            "[Epoch 3/50] [Batch 0/600] [D loss: 0.6914935111999512] [G loss: 1.1624927520751953]\n",
            "[Epoch 3/50] [Batch 100/600] [D loss: 0.6597216129302979] [G loss: 1.1345384120941162]\n",
            "[Epoch 3/50] [Batch 200/600] [D loss: 0.6620808839797974] [G loss: 1.1216062307357788]\n",
            "[Epoch 3/50] [Batch 300/600] [D loss: 0.7196534276008606] [G loss: 1.0784553289413452]\n",
            "[Epoch 3/50] [Batch 400/600] [D loss: 0.6747274398803711] [G loss: 1.1225383281707764]\n",
            "[Epoch 3/50] [Batch 500/600] [D loss: 0.7143141031265259] [G loss: 1.0712779760360718]\n",
            "[Epoch 4/50] [Batch 0/600] [D loss: 0.6874457597732544] [G loss: 0.9948998689651489]\n",
            "[Epoch 4/50] [Batch 100/600] [D loss: 0.6899898052215576] [G loss: 1.0472252368927002]\n",
            "[Epoch 4/50] [Batch 200/600] [D loss: 0.6953575611114502] [G loss: 1.0029082298278809]\n",
            "[Epoch 4/50] [Batch 300/600] [D loss: 0.6732234954833984] [G loss: 1.0422332286834717]\n",
            "[Epoch 4/50] [Batch 400/600] [D loss: 0.6944530010223389] [G loss: 1.0079522132873535]\n",
            "[Epoch 4/50] [Batch 500/600] [D loss: 0.7036553621292114] [G loss: 0.9980573058128357]\n",
            "[Epoch 5/50] [Batch 0/600] [D loss: 0.6802681684494019] [G loss: 1.0084877014160156]\n",
            "[Epoch 5/50] [Batch 100/600] [D loss: 0.7138115167617798] [G loss: 0.9876576662063599]\n",
            "[Epoch 5/50] [Batch 200/600] [D loss: 0.7052510976791382] [G loss: 0.961634635925293]\n",
            "[Epoch 5/50] [Batch 300/600] [D loss: 0.7167668342590332] [G loss: 0.9447916746139526]\n",
            "[Epoch 5/50] [Batch 400/600] [D loss: 0.7051588296890259] [G loss: 0.8890593647956848]\n",
            "[Epoch 5/50] [Batch 500/600] [D loss: 0.6774589419364929] [G loss: 0.9676389098167419]\n",
            "[Epoch 6/50] [Batch 0/600] [D loss: 0.6832133531570435] [G loss: 0.9539793133735657]\n",
            "[Epoch 6/50] [Batch 100/600] [D loss: 0.6439194679260254] [G loss: 1.0666533708572388]\n",
            "[Epoch 6/50] [Batch 200/600] [D loss: 0.6814782619476318] [G loss: 0.9797025918960571]\n",
            "[Epoch 6/50] [Batch 300/600] [D loss: 0.7174050807952881] [G loss: 0.9314595460891724]\n",
            "[Epoch 6/50] [Batch 400/600] [D loss: 0.6777634620666504] [G loss: 0.993596076965332]\n",
            "[Epoch 6/50] [Batch 500/600] [D loss: 0.7006136178970337] [G loss: 0.9722169041633606]\n",
            "[Epoch 7/50] [Batch 0/600] [D loss: 0.694422721862793] [G loss: 0.9141237735748291]\n",
            "[Epoch 7/50] [Batch 100/600] [D loss: 0.7003198862075806] [G loss: 0.9226240515708923]\n",
            "[Epoch 7/50] [Batch 200/600] [D loss: 0.693803071975708] [G loss: 0.9403256177902222]\n",
            "[Epoch 7/50] [Batch 300/600] [D loss: 0.7054278254508972] [G loss: 0.9013378024101257]\n",
            "[Epoch 7/50] [Batch 400/600] [D loss: 0.6897143125534058] [G loss: 0.9192477464675903]\n",
            "[Epoch 7/50] [Batch 500/600] [D loss: 0.682374119758606] [G loss: 0.9353200197219849]\n",
            "[Epoch 8/50] [Batch 0/600] [D loss: 0.7006981372833252] [G loss: 0.9617564678192139]\n",
            "[Epoch 8/50] [Batch 100/600] [D loss: 0.6322647333145142] [G loss: 1.7311538457870483]\n",
            "[Epoch 8/50] [Batch 200/600] [D loss: 0.6940927505493164] [G loss: 1.0503840446472168]\n",
            "[Epoch 8/50] [Batch 300/600] [D loss: 0.7222088575363159] [G loss: 0.9409542083740234]\n",
            "[Epoch 8/50] [Batch 400/600] [D loss: 0.6738148927688599] [G loss: 0.959326982498169]\n",
            "[Epoch 8/50] [Batch 500/600] [D loss: 0.6766719818115234] [G loss: 1.0137697458267212]\n",
            "[Epoch 9/50] [Batch 0/600] [D loss: 0.6928335428237915] [G loss: 0.9306703805923462]\n",
            "[Epoch 9/50] [Batch 100/600] [D loss: 0.7221695184707642] [G loss: 0.8975571990013123]\n",
            "[Epoch 9/50] [Batch 200/600] [D loss: 0.676544189453125] [G loss: 1.0093506574630737]\n",
            "[Epoch 9/50] [Batch 300/600] [D loss: 0.7028895616531372] [G loss: 0.8547195196151733]\n",
            "[Epoch 9/50] [Batch 400/600] [D loss: 0.6929917335510254] [G loss: 0.9452541470527649]\n",
            "[Epoch 9/50] [Batch 500/600] [D loss: 0.7069319486618042] [G loss: 0.9311126470565796]\n",
            "[Epoch 10/50] [Batch 0/600] [D loss: 0.6928957104682922] [G loss: 0.908677339553833]\n",
            "[Epoch 10/50] [Batch 100/600] [D loss: 0.6965732574462891] [G loss: 0.873532235622406]\n",
            "[Epoch 10/50] [Batch 200/600] [D loss: 0.686112105846405] [G loss: 0.9305667877197266]\n",
            "[Epoch 10/50] [Batch 300/600] [D loss: 0.6865119934082031] [G loss: 0.8876897096633911]\n",
            "[Epoch 10/50] [Batch 400/600] [D loss: 0.7126756310462952] [G loss: 0.8817476034164429]\n",
            "[Epoch 10/50] [Batch 500/600] [D loss: 0.6774967908859253] [G loss: 0.9295575022697449]\n",
            "[Epoch 11/50] [Batch 0/600] [D loss: 0.6790899634361267] [G loss: 0.9235485792160034]\n",
            "[Epoch 11/50] [Batch 100/600] [D loss: 0.7143089771270752] [G loss: 0.9091865420341492]\n",
            "[Epoch 11/50] [Batch 200/600] [D loss: 0.7051247954368591] [G loss: 0.8511788845062256]\n",
            "[Epoch 11/50] [Batch 300/600] [D loss: 0.7018654346466064] [G loss: 0.9138267636299133]\n",
            "[Epoch 11/50] [Batch 400/600] [D loss: 0.6714856028556824] [G loss: 0.9590235352516174]\n",
            "[Epoch 11/50] [Batch 500/600] [D loss: 0.6746600866317749] [G loss: 0.9132872819900513]\n",
            "[Epoch 12/50] [Batch 0/600] [D loss: 0.686532735824585] [G loss: 0.9045892953872681]\n",
            "[Epoch 12/50] [Batch 100/600] [D loss: 0.6826802492141724] [G loss: 0.9084993600845337]\n",
            "[Epoch 12/50] [Batch 200/600] [D loss: 0.7110596895217896] [G loss: 0.8730300664901733]\n",
            "[Epoch 12/50] [Batch 300/600] [D loss: 0.6913368701934814] [G loss: 0.9070516228675842]\n",
            "[Epoch 12/50] [Batch 400/600] [D loss: 0.7244216799736023] [G loss: 0.9353690147399902]\n",
            "[Epoch 12/50] [Batch 500/600] [D loss: 0.6833211183547974] [G loss: 0.8476457595825195]\n",
            "[Epoch 13/50] [Batch 0/600] [D loss: 0.7115923166275024] [G loss: 0.8525761365890503]\n",
            "[Epoch 13/50] [Batch 100/600] [D loss: 0.7168453931808472] [G loss: 0.9268360137939453]\n",
            "[Epoch 13/50] [Batch 200/600] [D loss: 0.6836388111114502] [G loss: 0.989480197429657]\n",
            "[Epoch 13/50] [Batch 300/600] [D loss: 0.6893608570098877] [G loss: 0.9520634412765503]\n",
            "[Epoch 13/50] [Batch 400/600] [D loss: 0.693689227104187] [G loss: 0.8785674571990967]\n",
            "[Epoch 13/50] [Batch 500/600] [D loss: 0.7074602246284485] [G loss: 0.8698906898498535]\n",
            "[Epoch 14/50] [Batch 0/600] [D loss: 0.6836292743682861] [G loss: 0.8811282515525818]\n",
            "[Epoch 14/50] [Batch 100/600] [D loss: 0.6810908913612366] [G loss: 0.8753975033760071]\n",
            "[Epoch 14/50] [Batch 200/600] [D loss: 0.6534810066223145] [G loss: 0.9014491438865662]\n",
            "[Epoch 14/50] [Batch 300/600] [D loss: 0.6731162667274475] [G loss: 0.9035719037055969]\n",
            "[Epoch 14/50] [Batch 400/600] [D loss: 0.7060613632202148] [G loss: 0.877648115158081]\n",
            "[Epoch 14/50] [Batch 500/600] [D loss: 0.7086759805679321] [G loss: 0.8718725442886353]\n",
            "[Epoch 15/50] [Batch 0/600] [D loss: 0.6854531764984131] [G loss: 0.8697627782821655]\n",
            "[Epoch 15/50] [Batch 100/600] [D loss: 0.6903557777404785] [G loss: 0.8548651933670044]\n",
            "[Epoch 15/50] [Batch 200/600] [D loss: 0.68186354637146] [G loss: 0.9065573215484619]\n",
            "[Epoch 15/50] [Batch 300/600] [D loss: 0.6998408436775208] [G loss: 0.9250106811523438]\n",
            "[Epoch 15/50] [Batch 400/600] [D loss: 0.651623010635376] [G loss: 0.987328827381134]\n",
            "[Epoch 15/50] [Batch 500/600] [D loss: 0.6938601732254028] [G loss: 0.9247426986694336]\n",
            "[Epoch 16/50] [Batch 0/600] [D loss: 0.6894762516021729] [G loss: 0.8916956186294556]\n",
            "[Epoch 16/50] [Batch 100/600] [D loss: 0.6802762746810913] [G loss: 0.9213277697563171]\n",
            "[Epoch 16/50] [Batch 200/600] [D loss: 0.6867323517799377] [G loss: 0.8703112006187439]\n",
            "[Epoch 16/50] [Batch 300/600] [D loss: 0.66585373878479] [G loss: 0.9601109623908997]\n",
            "[Epoch 16/50] [Batch 400/600] [D loss: 0.6652487516403198] [G loss: 0.9174219965934753]\n",
            "[Epoch 16/50] [Batch 500/600] [D loss: 0.6674553751945496] [G loss: 0.922040581703186]\n",
            "[Epoch 17/50] [Batch 0/600] [D loss: 0.689163327217102] [G loss: 0.8712537288665771]\n",
            "[Epoch 17/50] [Batch 100/600] [D loss: 0.6920558214187622] [G loss: 0.8961448669433594]\n",
            "[Epoch 17/50] [Batch 200/600] [D loss: 0.6840975284576416] [G loss: 0.8861502408981323]\n",
            "[Epoch 17/50] [Batch 300/600] [D loss: 0.5846480131149292] [G loss: 1.2485384941101074]\n",
            "[Epoch 17/50] [Batch 400/600] [D loss: 0.710379958152771] [G loss: 0.852712869644165]\n",
            "[Epoch 17/50] [Batch 500/600] [D loss: 0.6832355260848999] [G loss: 0.9295819401741028]\n",
            "[Epoch 18/50] [Batch 0/600] [D loss: 0.674219012260437] [G loss: 0.8953092098236084]\n",
            "[Epoch 18/50] [Batch 100/600] [D loss: 0.6782281398773193] [G loss: 0.8858226537704468]\n",
            "[Epoch 18/50] [Batch 200/600] [D loss: 0.7185330390930176] [G loss: 0.8556714653968811]\n",
            "[Epoch 18/50] [Batch 300/600] [D loss: 0.6803097724914551] [G loss: 0.9000430107116699]\n",
            "[Epoch 18/50] [Batch 400/600] [D loss: 0.677061140537262] [G loss: 0.8628735542297363]\n",
            "[Epoch 18/50] [Batch 500/600] [D loss: 0.7084612846374512] [G loss: 0.8609424233436584]\n",
            "[Epoch 19/50] [Batch 0/600] [D loss: 0.6761893033981323] [G loss: 0.9139693975448608]\n",
            "[Epoch 19/50] [Batch 100/600] [D loss: 0.6883509159088135] [G loss: 0.9215043187141418]\n",
            "[Epoch 19/50] [Batch 200/600] [D loss: 0.6638106107711792] [G loss: 0.8795469999313354]\n",
            "[Epoch 19/50] [Batch 300/600] [D loss: 0.6554636359214783] [G loss: 0.9434307217597961]\n",
            "[Epoch 19/50] [Batch 400/600] [D loss: 0.750352144241333] [G loss: 0.8598623275756836]\n",
            "[Epoch 19/50] [Batch 500/600] [D loss: 0.6558270454406738] [G loss: 0.8953967094421387]\n",
            "[Epoch 20/50] [Batch 0/600] [D loss: 0.6693302989006042] [G loss: 0.8879665732383728]\n",
            "[Epoch 20/50] [Batch 100/600] [D loss: 0.6952497959136963] [G loss: 0.8938449621200562]\n",
            "[Epoch 20/50] [Batch 200/600] [D loss: 0.7023974657058716] [G loss: 0.8351244926452637]\n",
            "[Epoch 20/50] [Batch 300/600] [D loss: 0.6919012069702148] [G loss: 0.8480967283248901]\n",
            "[Epoch 20/50] [Batch 400/600] [D loss: 0.6977810859680176] [G loss: 0.8824260234832764]\n",
            "[Epoch 20/50] [Batch 500/600] [D loss: 0.6788215637207031] [G loss: 0.8771781921386719]\n",
            "[Epoch 21/50] [Batch 0/600] [D loss: 0.6803895235061646] [G loss: 0.8842214941978455]\n",
            "[Epoch 21/50] [Batch 100/600] [D loss: 0.6956189870834351] [G loss: 0.8583202362060547]\n",
            "[Epoch 21/50] [Batch 200/600] [D loss: 0.695763349533081] [G loss: 0.8825618028640747]\n",
            "[Epoch 21/50] [Batch 300/600] [D loss: 0.7000881433486938] [G loss: 0.8498756885528564]\n",
            "[Epoch 21/50] [Batch 400/600] [D loss: 0.6869646906852722] [G loss: 0.8750663995742798]\n",
            "[Epoch 21/50] [Batch 500/600] [D loss: 0.7043228149414062] [G loss: 0.8685716390609741]\n",
            "[Epoch 22/50] [Batch 0/600] [D loss: 0.701556921005249] [G loss: 0.8594428896903992]\n",
            "[Epoch 22/50] [Batch 100/600] [D loss: 0.7138829827308655] [G loss: 0.8079753518104553]\n",
            "[Epoch 22/50] [Batch 200/600] [D loss: 0.6705864667892456] [G loss: 0.8635713458061218]\n",
            "[Epoch 22/50] [Batch 300/600] [D loss: 0.7027985453605652] [G loss: 0.8691657185554504]\n",
            "[Epoch 22/50] [Batch 400/600] [D loss: 0.683499813079834] [G loss: 0.8504592180252075]\n",
            "[Epoch 22/50] [Batch 500/600] [D loss: 0.67451012134552] [G loss: 0.8497531414031982]\n",
            "[Epoch 23/50] [Batch 0/600] [D loss: 0.5310198664665222] [G loss: 1.1728237867355347]\n",
            "[Epoch 23/50] [Batch 100/600] [D loss: 0.6581366062164307] [G loss: 0.9593266844749451]\n",
            "[Epoch 23/50] [Batch 200/600] [D loss: 0.6640126705169678] [G loss: 1.2139233350753784]\n",
            "[Epoch 23/50] [Batch 300/600] [D loss: 0.8577675819396973] [G loss: 0.9202406406402588]\n",
            "[Epoch 23/50] [Batch 400/600] [D loss: 0.6290216445922852] [G loss: 1.1413702964782715]\n",
            "[Epoch 23/50] [Batch 500/600] [D loss: 0.6617593765258789] [G loss: 1.359220027923584]\n",
            "[Epoch 24/50] [Batch 0/600] [D loss: 0.39852359890937805] [G loss: 1.5565577745437622]\n",
            "[Epoch 24/50] [Batch 100/600] [D loss: 0.616157591342926] [G loss: 1.0978670120239258]\n",
            "[Epoch 24/50] [Batch 200/600] [D loss: 0.7679219245910645] [G loss: 1.014587640762329]\n",
            "[Epoch 24/50] [Batch 300/600] [D loss: 0.6338294148445129] [G loss: 1.1141279935836792]\n",
            "[Epoch 24/50] [Batch 400/600] [D loss: 0.3319104313850403] [G loss: 1.9888312816619873]\n",
            "[Epoch 24/50] [Batch 500/600] [D loss: 0.5774368047714233] [G loss: 1.170140027999878]\n",
            "[Epoch 25/50] [Batch 0/600] [D loss: 0.7800289392471313] [G loss: 1.0924413204193115]\n",
            "[Epoch 25/50] [Batch 100/600] [D loss: 0.4727499485015869] [G loss: 1.228973150253296]\n",
            "[Epoch 25/50] [Batch 200/600] [D loss: 0.5649530291557312] [G loss: 1.2567763328552246]\n",
            "[Epoch 25/50] [Batch 300/600] [D loss: 0.32912349700927734] [G loss: 1.8258692026138306]\n",
            "[Epoch 25/50] [Batch 400/600] [D loss: 0.39970529079437256] [G loss: 1.6992149353027344]\n",
            "[Epoch 25/50] [Batch 500/600] [D loss: 0.4439258277416229] [G loss: 1.6549001932144165]\n",
            "[Epoch 26/50] [Batch 0/600] [D loss: 0.49405965209007263] [G loss: 1.4905848503112793]\n",
            "[Epoch 26/50] [Batch 100/600] [D loss: 0.5355135202407837] [G loss: 1.3311303853988647]\n",
            "[Epoch 26/50] [Batch 200/600] [D loss: 0.6109862923622131] [G loss: 0.9038113951683044]\n",
            "[Epoch 26/50] [Batch 300/600] [D loss: 0.44202110171318054] [G loss: 1.3384318351745605]\n",
            "[Epoch 26/50] [Batch 400/600] [D loss: 0.5646548271179199] [G loss: 1.2987425327301025]\n",
            "[Epoch 26/50] [Batch 500/600] [D loss: 0.5397032499313354] [G loss: 1.1264888048171997]\n",
            "[Epoch 27/50] [Batch 0/600] [D loss: 0.35394829511642456] [G loss: 1.5494846105575562]\n",
            "[Epoch 27/50] [Batch 100/600] [D loss: 0.3180399239063263] [G loss: 1.6112931966781616]\n",
            "[Epoch 27/50] [Batch 200/600] [D loss: 0.6714718341827393] [G loss: 1.3313112258911133]\n",
            "[Epoch 27/50] [Batch 300/600] [D loss: 0.5747159123420715] [G loss: 1.4117934703826904]\n",
            "[Epoch 27/50] [Batch 400/600] [D loss: 0.5431586503982544] [G loss: 1.1195831298828125]\n",
            "[Epoch 27/50] [Batch 500/600] [D loss: 0.3580225110054016] [G loss: 1.5126993656158447]\n",
            "[Epoch 28/50] [Batch 0/600] [D loss: 0.45000332593917847] [G loss: 1.3179011344909668]\n",
            "[Epoch 28/50] [Batch 100/600] [D loss: 0.7313567399978638] [G loss: 0.9058306217193604]\n",
            "[Epoch 28/50] [Batch 200/600] [D loss: 0.6862635612487793] [G loss: 1.050297498703003]\n",
            "[Epoch 28/50] [Batch 300/600] [D loss: 0.2781229019165039] [G loss: 1.8364368677139282]\n",
            "[Epoch 28/50] [Batch 400/600] [D loss: 0.36947333812713623] [G loss: 1.6081769466400146]\n",
            "[Epoch 28/50] [Batch 500/600] [D loss: 0.3442378640174866] [G loss: 1.9891873598098755]\n",
            "[Epoch 29/50] [Batch 0/600] [D loss: 0.2276511937379837] [G loss: 1.8831881284713745]\n",
            "[Epoch 29/50] [Batch 100/600] [D loss: 0.44164490699768066] [G loss: 1.4167020320892334]\n",
            "[Epoch 29/50] [Batch 200/600] [D loss: 0.3914680480957031] [G loss: 1.38347327709198]\n",
            "[Epoch 29/50] [Batch 300/600] [D loss: 0.5644776225090027] [G loss: 1.1173629760742188]\n",
            "[Epoch 29/50] [Batch 400/600] [D loss: 0.6881613731384277] [G loss: 0.986909031867981]\n",
            "[Epoch 29/50] [Batch 500/600] [D loss: 0.3887381851673126] [G loss: 1.6538933515548706]\n",
            "[Epoch 30/50] [Batch 0/600] [D loss: 0.5018024444580078] [G loss: 1.3206298351287842]\n",
            "[Epoch 30/50] [Batch 100/600] [D loss: 0.5309855937957764] [G loss: 1.1288002729415894]\n",
            "[Epoch 30/50] [Batch 200/600] [D loss: 0.4353330135345459] [G loss: 1.8160892724990845]\n",
            "[Epoch 30/50] [Batch 300/600] [D loss: 0.34533774852752686] [G loss: 1.7727808952331543]\n",
            "[Epoch 30/50] [Batch 400/600] [D loss: 0.6334270238876343] [G loss: 1.029386281967163]\n",
            "[Epoch 30/50] [Batch 500/600] [D loss: 0.32488811016082764] [G loss: 1.5580898523330688]\n",
            "[Epoch 31/50] [Batch 0/600] [D loss: 0.40818437933921814] [G loss: 1.546854019165039]\n",
            "[Epoch 31/50] [Batch 100/600] [D loss: 0.12405139207839966] [G loss: 2.6795384883880615]\n",
            "[Epoch 31/50] [Batch 200/600] [D loss: 0.19809496402740479] [G loss: 2.2998292446136475]\n",
            "[Epoch 31/50] [Batch 300/600] [D loss: 0.38209015130996704] [G loss: 1.7304730415344238]\n",
            "[Epoch 31/50] [Batch 400/600] [D loss: 0.3842671811580658] [G loss: 2.1210997104644775]\n",
            "[Epoch 31/50] [Batch 500/600] [D loss: 0.22713926434516907] [G loss: 2.820460081100464]\n",
            "[Epoch 32/50] [Batch 0/600] [D loss: 0.373140811920166] [G loss: 2.0496859550476074]\n",
            "[Epoch 32/50] [Batch 100/600] [D loss: 0.7584474682807922] [G loss: 1.8055609464645386]\n",
            "[Epoch 32/50] [Batch 200/600] [D loss: 0.5687097311019897] [G loss: 1.8669997453689575]\n",
            "[Epoch 32/50] [Batch 300/600] [D loss: 0.45664599537849426] [G loss: 1.9532703161239624]\n",
            "[Epoch 32/50] [Batch 400/600] [D loss: 0.6790370941162109] [G loss: 1.1615644693374634]\n",
            "[Epoch 32/50] [Batch 500/600] [D loss: 0.3422827124595642] [G loss: 1.678748607635498]\n",
            "[Epoch 33/50] [Batch 0/600] [D loss: 0.617179274559021] [G loss: 1.1464835405349731]\n",
            "[Epoch 33/50] [Batch 100/600] [D loss: 0.3498443365097046] [G loss: 1.570749282836914]\n",
            "[Epoch 33/50] [Batch 200/600] [D loss: 0.5660119652748108] [G loss: 1.360169768333435]\n",
            "[Epoch 33/50] [Batch 300/600] [D loss: 0.534446656703949] [G loss: 1.1523387432098389]\n",
            "[Epoch 33/50] [Batch 400/600] [D loss: 0.2634713053703308] [G loss: 2.0988612174987793]\n",
            "[Epoch 33/50] [Batch 500/600] [D loss: 0.44754457473754883] [G loss: 1.4443196058273315]\n",
            "[Epoch 34/50] [Batch 0/600] [D loss: 0.46278446912765503] [G loss: 2.1272313594818115]\n",
            "[Epoch 34/50] [Batch 100/600] [D loss: 0.5464081764221191] [G loss: 1.4231722354888916]\n",
            "[Epoch 34/50] [Batch 200/600] [D loss: 0.5280661582946777] [G loss: 1.277336597442627]\n",
            "[Epoch 34/50] [Batch 300/600] [D loss: 0.36918574571609497] [G loss: 1.5428359508514404]\n",
            "[Epoch 34/50] [Batch 400/600] [D loss: 0.7972747683525085] [G loss: 1.1220982074737549]\n",
            "[Epoch 34/50] [Batch 500/600] [D loss: 0.5053279399871826] [G loss: 1.4760303497314453]\n",
            "[Epoch 35/50] [Batch 0/600] [D loss: 0.32613980770111084] [G loss: 1.852036476135254]\n",
            "[Epoch 35/50] [Batch 100/600] [D loss: 0.49308887124061584] [G loss: 1.3112852573394775]\n",
            "[Epoch 35/50] [Batch 200/600] [D loss: 0.36622703075408936] [G loss: 1.7422258853912354]\n",
            "[Epoch 35/50] [Batch 300/600] [D loss: 0.1569450944662094] [G loss: 2.646609306335449]\n",
            "[Epoch 35/50] [Batch 400/600] [D loss: 0.3645140826702118] [G loss: 1.691112995147705]\n",
            "[Epoch 35/50] [Batch 500/600] [D loss: 0.44946902990341187] [G loss: 1.324975848197937]\n",
            "[Epoch 36/50] [Batch 0/600] [D loss: 0.2902730405330658] [G loss: 1.7632107734680176]\n",
            "[Epoch 36/50] [Batch 100/600] [D loss: 0.40776199102401733] [G loss: 1.6212377548217773]\n",
            "[Epoch 36/50] [Batch 200/600] [D loss: 0.1682964563369751] [G loss: 3.080770254135132]\n",
            "[Epoch 36/50] [Batch 300/600] [D loss: 0.14314791560173035] [G loss: 2.2001304626464844]\n",
            "[Epoch 36/50] [Batch 400/600] [D loss: 0.5144528746604919] [G loss: 1.0380876064300537]\n",
            "[Epoch 36/50] [Batch 500/600] [D loss: 0.39688652753829956] [G loss: 1.4949352741241455]\n",
            "[Epoch 37/50] [Batch 0/600] [D loss: 0.3353293240070343] [G loss: 1.8854540586471558]\n",
            "[Epoch 37/50] [Batch 100/600] [D loss: 0.545159637928009] [G loss: 1.3982882499694824]\n",
            "[Epoch 37/50] [Batch 200/600] [D loss: 0.39374762773513794] [G loss: 2.2595162391662598]\n",
            "[Epoch 37/50] [Batch 300/600] [D loss: 0.19952845573425293] [G loss: 2.8003628253936768]\n",
            "[Epoch 37/50] [Batch 400/600] [D loss: 0.6030067801475525] [G loss: 1.1184048652648926]\n",
            "[Epoch 37/50] [Batch 500/600] [D loss: 0.528532087802887] [G loss: 2.413809061050415]\n",
            "[Epoch 38/50] [Batch 0/600] [D loss: 0.05994812399148941] [G loss: 3.20186448097229]\n",
            "[Epoch 38/50] [Batch 100/600] [D loss: 0.31069836020469666] [G loss: 1.6788609027862549]\n",
            "[Epoch 38/50] [Batch 200/600] [D loss: 0.32913655042648315] [G loss: 1.7996599674224854]\n",
            "[Epoch 38/50] [Batch 300/600] [D loss: 0.22918784618377686] [G loss: 1.8109523057937622]\n",
            "[Epoch 38/50] [Batch 400/600] [D loss: 0.43474704027175903] [G loss: 1.4669649600982666]\n",
            "[Epoch 38/50] [Batch 500/600] [D loss: 0.3779626488685608] [G loss: 1.3680267333984375]\n",
            "[Epoch 39/50] [Batch 0/600] [D loss: 0.23865921795368195] [G loss: 2.2377572059631348]\n",
            "[Epoch 39/50] [Batch 100/600] [D loss: 0.4735831618309021] [G loss: 2.198066473007202]\n",
            "[Epoch 39/50] [Batch 200/600] [D loss: 0.2208917737007141] [G loss: 2.202178478240967]\n",
            "[Epoch 39/50] [Batch 300/600] [D loss: 0.6527441740036011] [G loss: 1.0351611375808716]\n",
            "[Epoch 39/50] [Batch 400/600] [D loss: 0.42759186029434204] [G loss: 1.5042983293533325]\n",
            "[Epoch 39/50] [Batch 500/600] [D loss: 0.4961111545562744] [G loss: 2.0241522789001465]\n",
            "[Epoch 40/50] [Batch 0/600] [D loss: 0.5044475793838501] [G loss: 1.7356950044631958]\n",
            "[Epoch 40/50] [Batch 100/600] [D loss: 0.4685090184211731] [G loss: 1.7927123308181763]\n",
            "[Epoch 40/50] [Batch 200/600] [D loss: 0.2898750901222229] [G loss: 2.1402337551116943]\n",
            "[Epoch 40/50] [Batch 300/600] [D loss: 0.1930570900440216] [G loss: 2.4856977462768555]\n",
            "[Epoch 40/50] [Batch 400/600] [D loss: 0.31074556708335876] [G loss: 2.110320568084717]\n",
            "[Epoch 40/50] [Batch 500/600] [D loss: 0.41542211174964905] [G loss: 1.719597339630127]\n",
            "[Epoch 41/50] [Batch 0/600] [D loss: 0.4717649817466736] [G loss: 1.4159960746765137]\n",
            "[Epoch 41/50] [Batch 100/600] [D loss: 0.5906113386154175] [G loss: 1.2530959844589233]\n",
            "[Epoch 41/50] [Batch 200/600] [D loss: 0.6379980444908142] [G loss: 1.4986166954040527]\n",
            "[Epoch 41/50] [Batch 300/600] [D loss: 0.5616893768310547] [G loss: 1.3252042531967163]\n",
            "[Epoch 41/50] [Batch 400/600] [D loss: 0.5058082342147827] [G loss: 1.1708388328552246]\n",
            "[Epoch 41/50] [Batch 500/600] [D loss: 0.6509883999824524] [G loss: 1.3263447284698486]\n",
            "[Epoch 42/50] [Batch 0/600] [D loss: 0.36562246084213257] [G loss: 1.758509635925293]\n",
            "[Epoch 42/50] [Batch 100/600] [D loss: 0.4082316756248474] [G loss: 1.6769447326660156]\n",
            "[Epoch 42/50] [Batch 200/600] [D loss: 0.6746232509613037] [G loss: 1.18064284324646]\n",
            "[Epoch 42/50] [Batch 300/600] [D loss: 0.25192490220069885] [G loss: 2.031940460205078]\n",
            "[Epoch 42/50] [Batch 400/600] [D loss: 0.3044058382511139] [G loss: 1.6088688373565674]\n",
            "[Epoch 42/50] [Batch 500/600] [D loss: 0.27509060502052307] [G loss: 2.7173690795898438]\n",
            "[Epoch 43/50] [Batch 0/600] [D loss: 0.48409849405288696] [G loss: 1.5684292316436768]\n",
            "[Epoch 43/50] [Batch 100/600] [D loss: 0.18916361033916473] [G loss: 2.047145366668701]\n",
            "[Epoch 43/50] [Batch 200/600] [D loss: 0.428071528673172] [G loss: 1.5000476837158203]\n",
            "[Epoch 43/50] [Batch 300/600] [D loss: 0.5016038417816162] [G loss: 1.5704643726348877]\n",
            "[Epoch 43/50] [Batch 400/600] [D loss: 0.396709680557251] [G loss: 2.249565601348877]\n",
            "[Epoch 43/50] [Batch 500/600] [D loss: 0.5247582197189331] [G loss: 2.55322527885437]\n",
            "[Epoch 44/50] [Batch 0/600] [D loss: 0.36977535486221313] [G loss: 1.5995302200317383]\n",
            "[Epoch 44/50] [Batch 100/600] [D loss: 0.36054348945617676] [G loss: 2.306180477142334]\n",
            "[Epoch 44/50] [Batch 200/600] [D loss: 0.42446744441986084] [G loss: 2.200777053833008]\n",
            "[Epoch 44/50] [Batch 300/600] [D loss: 0.372315913438797] [G loss: 2.640378475189209]\n",
            "[Epoch 44/50] [Batch 400/600] [D loss: 0.5013868808746338] [G loss: 1.1215307712554932]\n",
            "[Epoch 44/50] [Batch 500/600] [D loss: 0.36941173672676086] [G loss: 2.3364667892456055]\n",
            "[Epoch 45/50] [Batch 0/600] [D loss: 0.3042932152748108] [G loss: 1.677372694015503]\n",
            "[Epoch 45/50] [Batch 100/600] [D loss: 0.2772428095340729] [G loss: 2.540353775024414]\n",
            "[Epoch 45/50] [Batch 200/600] [D loss: 0.44110429286956787] [G loss: 2.157647132873535]\n",
            "[Epoch 45/50] [Batch 300/600] [D loss: 0.27368974685668945] [G loss: 1.9070374965667725]\n",
            "[Epoch 45/50] [Batch 400/600] [D loss: 0.5335713624954224] [G loss: 1.226578950881958]\n",
            "[Epoch 45/50] [Batch 500/600] [D loss: 0.4594029188156128] [G loss: 1.2407118082046509]\n",
            "[Epoch 46/50] [Batch 0/600] [D loss: 0.27663344144821167] [G loss: 2.184696674346924]\n",
            "[Epoch 46/50] [Batch 100/600] [D loss: 0.537363588809967] [G loss: 2.3364617824554443]\n",
            "[Epoch 46/50] [Batch 200/600] [D loss: 0.2944806218147278] [G loss: 1.963678240776062]\n",
            "[Epoch 46/50] [Batch 300/600] [D loss: 0.25314047932624817] [G loss: 1.9551260471343994]\n",
            "[Epoch 46/50] [Batch 400/600] [D loss: 0.3105543255805969] [G loss: 1.6956281661987305]\n",
            "[Epoch 46/50] [Batch 500/600] [D loss: 0.42652538418769836] [G loss: 1.7531569004058838]\n",
            "[Epoch 47/50] [Batch 0/600] [D loss: 0.4331400394439697] [G loss: 1.9597498178482056]\n",
            "[Epoch 47/50] [Batch 100/600] [D loss: 0.5270569324493408] [G loss: 1.315704345703125]\n",
            "[Epoch 47/50] [Batch 200/600] [D loss: 0.3325076103210449] [G loss: 2.0095982551574707]\n",
            "[Epoch 47/50] [Batch 300/600] [D loss: 0.5472390651702881] [G loss: 1.32723867893219]\n",
            "[Epoch 47/50] [Batch 400/600] [D loss: 0.4913575053215027] [G loss: 1.680159568786621]\n",
            "[Epoch 47/50] [Batch 500/600] [D loss: 0.40183025598526] [G loss: 1.7677093744277954]\n",
            "[Epoch 48/50] [Batch 0/600] [D loss: 0.2795168161392212] [G loss: 1.8149168491363525]\n",
            "[Epoch 48/50] [Batch 100/600] [D loss: 0.15805360674858093] [G loss: 2.4378132820129395]\n",
            "[Epoch 48/50] [Batch 200/600] [D loss: 0.3632047176361084] [G loss: 1.327800989151001]\n",
            "[Epoch 48/50] [Batch 300/600] [D loss: 0.760132372379303] [G loss: 0.8288188576698303]\n",
            "[Epoch 48/50] [Batch 400/600] [D loss: 0.321584016084671] [G loss: 2.3256607055664062]\n",
            "[Epoch 48/50] [Batch 500/600] [D loss: 0.23660029470920563] [G loss: 2.49582576751709]\n",
            "[Epoch 49/50] [Batch 0/600] [D loss: 0.44290781021118164] [G loss: 2.912250518798828]\n",
            "[Epoch 49/50] [Batch 100/600] [D loss: 0.5480973720550537] [G loss: 1.8568307161331177]\n",
            "[Epoch 49/50] [Batch 200/600] [D loss: 0.47870126366615295] [G loss: 1.871926188468933]\n",
            "[Epoch 49/50] [Batch 300/600] [D loss: 0.5301650762557983] [G loss: 1.4399219751358032]\n",
            "[Epoch 49/50] [Batch 400/600] [D loss: 0.34124755859375] [G loss: 1.5824155807495117]\n",
            "[Epoch 49/50] [Batch 500/600] [D loss: 0.6725598573684692] [G loss: 1.22393798828125]\n"
          ]
        }
      ],
      "source": [
        "# Assuming loaders['train'] is the larger dataset and loaders['target'] is the smaller dataset\n",
        "source_data_loader = loaders['train']\n",
        "target_data_loader = iter(cycle(loaders['target']))\n",
        "\n",
        "# Instantiate the CycleGAN generator (generator_G) and discriminator (discriminator_G)\n",
        "generator_G = CycleGANGenerator(input_channels=1)\n",
        "discriminator_G = CycleGANDiscriminator(input_channels=1)\n",
        "\n",
        "# Move the generator and discriminator to the appropriate device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator_G.to(device)\n",
        "discriminator_G.to(device)\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "\n",
        "generator_G.apply(weights_init_normal)\n",
        "discriminator_G.apply(weights_init_normal)\n",
        "\n",
        "# Set the generator_G and discriminator_G to training mode\n",
        "generator_G.train()\n",
        "discriminator_G.train()\n",
        "\n",
        "# Define the loss functions and optimizers\n",
        "criterion_GAN = nn.BCELoss()\n",
        "criterion_cycle = nn.L1Loss()\n",
        "optimizer_G = optim.Adam(generator_G.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator_G.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "\n",
        "# Training the CycleGAN generator and discriminator\n",
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    target_data_loader = iter(cycle(loaders['target']))  # Reset target_data_loader at the beginning of each epoch\n",
        "\n",
        "    for i, source_images in enumerate(source_data_loader):\n",
        "        source_images = source_images[0].to(device)\n",
        "\n",
        "        # Dynamically adjust the target batch size to match the source batch size\n",
        "        target_batch_size = source_images.size(0)\n",
        "        target_images = []\n",
        "\n",
        "        while len(target_images) < target_batch_size:\n",
        "            try:\n",
        "                target_batch = next(target_data_loader)[0].to(device)\n",
        "                target_images.extend(target_batch)\n",
        "            except StopIteration:\n",
        "                target_data_loader = iter(cycle(loaders['target']))  # Reset target_data_loader if exhausted\n",
        "                continue\n",
        "\n",
        "        target_images = torch.stack(target_images[:target_batch_size])\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = torch.ones((source_images.size(0), 1, discriminator_G(target_images).size(2), discriminator_G(target_images).size(3)), device=device)\n",
        "        fake = torch.zeros((source_images.size(0), 1, discriminator_G(target_images).size(2), discriminator_G(target_images).size(3)), device=device)\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # GAN loss\n",
        "        fake_images = generator_G(source_images)\n",
        "        pred_fake = discriminator_G(fake_images)\n",
        "        loss_GAN = criterion_GAN(pred_fake, valid)\n",
        "\n",
        "        # Cycle loss\n",
        "        reconstructed_images = generator_G(fake_images)\n",
        "        loss_cycle = criterion_cycle(reconstructed_images, source_images)\n",
        "\n",
        "        # Total loss\n",
        "        lambda_cycle = 5\n",
        "        loss_G = loss_GAN + lambda_cycle * loss_cycle\n",
        "\n",
        "        loss_G.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Real loss\n",
        "        pred_real = discriminator_G(source_images)\n",
        "        loss_real = criterion_GAN(pred_real, valid)\n",
        "\n",
        "        # Fake loss\n",
        "        pred_fake = discriminator_G(fake_images.detach())\n",
        "        loss_fake = criterion_GAN(pred_fake, fake)\n",
        "\n",
        "        # Total loss\n",
        "        loss_D = 0.5 * (loss_real + loss_fake)\n",
        "\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Print training information\n",
        "        if i % 100 == 0:\n",
        "            print(\n",
        "                f\"[Epoch {epoch}/{num_epochs}] [Batch {i}/{len(source_data_loader)}] [D loss: {loss_D.item()}] [G loss: {loss_G.item()}]\"\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# After training, you can visualize the generated images using the provided visualization function\n",
        "image_size = 28\n",
        "visualize_generated_images(generator_G, num_images=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j1leMHIYiQHK",
        "outputId": "0cb975f2-042b-44f7-cb35-2a4c14397e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = CNN()\n",
        "cnn_model.eval()\n",
        "\n",
        "# Define image preprocessing function\n",
        "def preprocess_image(image_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((28, 28)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "    ])\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  for _ in range(5):\n",
        "    # Generate a random input or use a sample from the test dataset\n",
        "    random_input = torch.randn(1, 1, image_size, image_size).to(device)\n",
        "    generated_image = generator_G(random_input)\n",
        "\n",
        "    preprocessed_image = transform(generated_image)\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        cnn_model.to(device)\n",
        "        preprocessed_image = preprocessed_image.to(device)\n",
        "        output = cnn_model(preprocessed_image)\n",
        "\n",
        "    # Process the output (e.g., obtain predicted class probabilities)\n",
        "    predicted_probs = nn.functional.softmax(output, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    # Visualize the generated image and predicted probabilities\n",
        "    plt.imshow(preprocessed_image.squeeze().cpu().numpy(), cmap='gray')\n",
        "    plt.title(f'Predicted Probabilities: {predicted_probs}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hjE_g7wdZCMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxOi1WIF3ScK"
      },
      "source": [
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUQDn_CmTG3s"
      },
      "outputs": [],
      "source": [
        "class CycleGANLayer(nn.Module):\n",
        "    def __init__(self, generator_G, generator_F):\n",
        "        super(CycleGANLayer, self).__init__()\n",
        "        self.generator_G = generator_G\n",
        "        #self.generator_F = generator_F\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        translated_images_G = self.generator_G(inputs)\n",
        "        #translated_images_F = self.generator_F(translated_images_G)\n",
        "        return translated_images_G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDQyyF6wVQz_",
        "outputId": "67f3e0d8-46b6-4ad8-92bf-2ba3e70343c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CycleGANGenerator(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu1): ReLU(inplace=True)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu2): ReLU(inplace=True)\n",
              "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu3): ReLU(inplace=True)\n",
              "  (residual_blocks): Sequential(\n",
              "    (0): ResidualBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): ResidualBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): ResidualBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): ResidualBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): ResidualBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): ResidualBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (deconv1): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "  (bn4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "  (relu4): ReLU(inplace=True)\n",
              "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
              "  (bn5): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "  (relu5): ReLU(inplace=True)\n",
              "  (output_layer): Conv2d(64, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "  (tanh): Tanh()\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generator_G = CycleGANGenerator(input_channels=1)\n",
        "\n",
        "# Move the generator to the appropriate device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator_G.to(device)\n",
        "\n",
        "# Set the generator_G to evaluation mode\n",
        "generator_G.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEH5Em-slY4t"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST to USPS"
      ],
      "metadata": {
        "id": "gSEBp9z3xj_W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7tQtzoylZXb"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBNVcfOly7uH",
        "outputId": "6c2ea304-1d27-42a2-c8a2-21c462daa06d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Semester 1/AI6121 Computer Vision/Group Project/'\n",
        "# Specify the name of the uploaded zip file\n",
        "zip_file_name = path + \"mnist2usps.zip\"\n",
        "storepath = path + \"dataset\"\n"
      ],
      "metadata": {
        "id": "qMi8MVHanej8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxlZrz9ko6hp",
        "outputId": "94eb5bb3-b7e3-463c-8c06-70eb249ff184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Files: ['mnist2usps']\n"
          ]
        }
      ],
      "source": [
        "# Extract the contents of the zip file\n",
        "with ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(storepath)\n",
        "\n",
        "# Check the extracted files\n",
        "extracted_files = os.listdir(storepath)\n",
        "print(\"Extracted Files:\", extracted_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKeapA6npArh"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, folder_path, transform=None):\n",
        "        self.folder_path = folder_path\n",
        "        self.transform = transform\n",
        "        # self.classes = os.listdir(folder_path)\n",
        "\n",
        "        # self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "        self.images = self._load_images()\n",
        "\n",
        "    def _load_images(self):\n",
        "        images = []\n",
        "        # print(self.classes)\n",
        "        # for cls in self.classes:\n",
        "            # class_path = os.path.join(self.folder_path, cls)\n",
        "        if os.path.isdir(self.folder_path):\n",
        "            for img_name in os.listdir(self.folder_path):\n",
        "                img_path = os.path.join(self.folder_path, img_name)\n",
        "                label = img_path.split(\"/\")[-1][0]\n",
        "                images.append((img_path, label))\n",
        "        return images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.images[idx]\n",
        "        image = Image.open(img_path).convert(\"L\")  # Convert to grayscale\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            label = torch.tensor(int(label))\n",
        "            # label = transforms.ToTensor(label)\n",
        "\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Define data transformation\n",
        "transform = transforms.Compose([\n",
        "    Resize(size = (28,28)),\n",
        "    Grayscale(),\n",
        "    # transforms.RandomCrop(224),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.5], std=[0.5])\n",
        "\n",
        "])\n",
        "\n",
        "# Create a custom dataset\n",
        "dataset = CustomDataset(folder_path=storepath + \"/mnist2usps\", transform=transform)\n",
        "\n",
        "# Create a data loader\n",
        "batch_size = 100\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAYwO_YK7iOj",
        "outputId": "7b7b2771-2fc4-434e-fa1e-dcce097f2770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYU0HeCDpTQd"
      },
      "outputs": [],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        # Your convolutional layers go here\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        # Linear layer with dynamic input size\n",
        "        self.out = nn.Linear(self._get_conv_output_size((1, 1, 28, 28)), 10)\n",
        "        # Dropout layer to add regularization\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def _get_conv_output_size(self, shape):\n",
        "        x = torch.rand(*shape)\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        return x.view(x.size(0), -1).shape[1]  # Return the number of features\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Your forward pass code goes here\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "\n",
        "        # Flatten the output of conv layers\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Linear layer\n",
        "        output = self.out(x)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "913SFkRXpzsd"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model\n",
        "model = CNNModel()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in data_loader:\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNQytVWmqEGD",
        "outputId": "5bca9726-7d47-4260-a2e4-367b44dbd182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2007\n",
            "Test Accuracy: 44.00%\n",
            "Average Test Loss: 14.8366\n"
          ]
        }
      ],
      "source": [
        " # Put the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize variables to track accuracy and loss\n",
        "correct = 0\n",
        "total = 0\n",
        "test_loss = 0.0\n",
        "\n",
        "# Iterate over the test dataset\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in loaders['target']:\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Update loss\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Get predictions\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Update accuracy\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "print(total)\n",
        "# Calculate accuracy and average loss\n",
        "accuracy = correct / total\n",
        "average_loss = test_loss / len(loaders['target'])\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Average Test Loss: {average_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEaS-5up-0w9"
      },
      "outputs": [],
      "source": [
        "cnn_2 = CNN()\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn_2.parameters(), lr = 0.01)\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train(num_epochs, cnn, loaders['test'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8NPSphgqfTD",
        "outputId": "290c4fe4-f44e-41a1-ac08-0694e0c8cad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/100], Loss: 0.0534\n",
            "Epoch [2/10], Step [100/100], Loss: 0.0318\n",
            "Epoch [3/10], Step [100/100], Loss: 0.0023\n",
            "Epoch [4/10], Step [100/100], Loss: 0.0810\n",
            "Epoch [5/10], Step [100/100], Loss: 0.0024\n",
            "Epoch [6/10], Step [100/100], Loss: 0.0658\n",
            "Epoch [7/10], Step [100/100], Loss: 0.0019\n",
            "Epoch [8/10], Step [100/100], Loss: 0.1584\n",
            "Epoch [9/10], Step [100/100], Loss: 0.0422\n",
            "Epoch [10/10], Step [100/100], Loss: 0.0040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model = cnn , test_loader = loaders['target'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-EEM9tjqoLz",
        "outputId": "a955bfd0-d097-45fe-cb94-e7e793c8261e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 2007 test images: 0.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cnn, path+\"/source_cnn_0.68.pt\")"
      ],
      "metadata": {
        "id": "_IqorZ29ve91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(num_epochs, cnn_2, data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grbopROAFujT",
        "outputId": "c6376a9b-39ea-4c4d-ff9e-43ff60bf12d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/100], Loss: 0.1169\n",
            "Epoch [2/10], Step [100/100], Loss: 0.0521\n",
            "Epoch [3/10], Step [100/100], Loss: 0.0388\n",
            "Epoch [4/10], Step [100/100], Loss: 0.1103\n",
            "Epoch [5/10], Step [100/100], Loss: 0.1315\n",
            "Epoch [6/10], Step [100/100], Loss: 0.0977\n",
            "Epoch [7/10], Step [100/100], Loss: 0.0124\n",
            "Epoch [8/10], Step [100/100], Loss: 0.0381\n",
            "Epoch [9/10], Step [100/100], Loss: 0.0168\n",
            "Epoch [10/10], Step [100/100], Loss: 0.0116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model = cnn_2 , test_loader = loaders['target'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D37j-GK5GKbg",
        "outputId": "07a30f69-0161-4e70-86bf-725ecdfa05ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 2007 test images: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_2 = torch.load(path+\"/adapted_cnn_0.90.pt\")"
      ],
      "metadata": {
        "id": "IFvgqXLf4aSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = torch.load(path+\"source_cnn_0.68.pt\")"
      ],
      "metadata": {
        "id": "Auh1Uy_oI9sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cnn_2, path+\"/adapted_cnn_0.90.pt\")"
      ],
      "metadata": {
        "id": "XfzeUm8dIs9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "wizJ68V2Iz6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the images\n",
        "img1 = cv2.imread('''/content/drive/MyDrive/Semester 1/AI6121 Computer Vision/Group Project/pytorch-CycleGAN-and-pix2pix/data/mnist_USPS/testA/0/00003.jpg''')\n",
        "img2 = cv2.imread('''/content/drive/MyDrive/Semester 1/AI6121 Computer Vision/Group Project/dataset/mnist2usps/0_00003_fake_B.png''')\n",
        "\n",
        "# vertically concatenates images\n",
        "# of same width\n",
        "# im_v = cv2.hconcat([img1, img2])\n",
        "# show the output image\n",
        "cv2_imshow(img1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "Cvo98gGI9IB4",
        "outputId": "1070daec-a7ef-424a-cbf7-7aa5e2813ab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAADnklEQVR4nO1VK0wzWxA++zq73YWWbp8kBAQEUlFFCBAIrjUogsLhIA0SR6rBAB4UCoMCgUYRDCEIEgSktFR00/RBX8vZPZ1fDOwtDdx7ufqO2Myex7ffzDczS8jPpus6IUTTNEKIIAiCIMiyTAgxDEMUxb+5+A9mmqaHi36v+Xw+dBRF6V0XfoLz+/22bTPGRFEURVEQBMdxfD4fOgCAZNH/HVPDMHRdFwRBURSPFyGEUvpBShDwk78AjUQi6BwdHTHGbm9vx8fHCSGyLCOQJEn4+m8Rh4aG8NrCwgIAAECn01lfX/eANE1DOFzx7EcRKaW1Wk3TtHg8vre3xxirVCqappmmibq5rmvbNvLtK4YfaeO5TCazvLycTCYppaZpcs4XFxctyyoWi3d3d9VqVVEUx3Ecx/ly2UuHFwI6AwMDhBAA4JzXajUMv9lsNhoNAHh8fJyZmSGf1ebp9mGecKIoSpIky7JXdJeXl+12G+FKpRJjrNVqvby8tFqt9/f3X1SS941UKlUoFBCx2+26rntwcJBKpebn57PZLOfccZxMJoMMDMP4Jn0YhRd+PB7P5XIAUK/Xq9VqLpfb3d0Nh8OyLA8ODg4PDzebzXK5XCwWt7a2otHo9wS9pCiKIstyIpHADALA1dWVqqo4Bzzb2NjAIGzbjsfjfW36pW0ppajS2NhYrVbjnOfz+VAohKIZhoGqmqYZiURubm4YY91ud3p6uj90BMVUdrtdzjkhZGRkJBAIiKI4OjqKlAkhAOC6riAIlUplcnJSkiTOOWNsc3OzL44POF3XUX1CSCAQyGazqDueUVW1txGj0eja2hpjDAAajUYymezPJjL1hFJVlRDy8PBg27bruviKGceTwWBwaWmpVCoBQLvdfn19TSQS/aDIjlKKN5H48/Ozx1SSJJx+hJBQKLS/vw8A5XIZAJ6enmZnZ/sG2F+goij2xogVyjlHRFyMxWLHx8eFQsGyLMzmxcWF3+/vp0m+DhgMUFGU6+trAHh7e0un06urq/f39/Bp2Ev4RH0opZilL0Ypxag9pjs7O5Zloe5YrfV6vV6vNxoN27YR/fDwENP1/TCllOKGV7NTU1PlcpkxVq1WPY6dTgcA8vn8+fn5xMREOBzGQGOx2Pe4mLjevbm5uZOTE8uyWq0WyoKUt7e3vfPYFKRnYnxYb9fjnqqq3qGVlZXT01MAODs7S6fTqVQqEokEg0HyWXz4/MXv5H/7b/YHPIbhoslJvRIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "T3yGvmNpBgBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_number"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGQ00NGTIfff",
        "outputId": "dbc51e91-27ab-4e8f-df0b-39c4f69a3c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1, 5, 1, 6, 4, 3, 4, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(loaders['target']))\n",
        "imgs, lbls = sample\n",
        "actual_number = lbls[:10].numpy()\n",
        "\n",
        "test_output, last_layer = cnn(imgs[:10])\n",
        "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
        "print(f'Source Model Prediction number:  {pred_y}')\n",
        "test_output, last_layer = cnn_2(imgs[:10])\n",
        "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
        "\n",
        "print(f'Adapted Model Prediction number: {pred_y}')\n",
        "print(f'Actual number:                   {actual_number}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdwyB9FtIlJH",
        "outputId": "4b31a5ef-7158-401e-ab84-331cdeae00ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Model Prediction number:  [1 3 1 4 4 5 0 0 4 3]\n",
            "Adapted Model Prediction number: [9 3 1 4 9 0 0 0 9 3]\n",
            "Actual number:                   [9 3 1 4 9 0 0 0 9 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P3x4c9c0IxTG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}